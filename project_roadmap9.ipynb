{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get data\n",
    "2. Create train-test split\n",
    "3. Clean training set (write functions): missing values, text, categorical attributes, scaling\n",
    "4. Select models and scoring metrics, then train\n",
    "5. Compare them: clean test set, make predictions, score\n",
    "6. Fine-tune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 292 entries, 2012-04-08 to 2017-11-05\n",
      "Columns: 1833 entries, 012 to TRUHONE\n",
      "dtypes: int64(1833)\n",
      "memory usage: 4.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>012</th>\n",
       "      <th>017</th>\n",
       "      <th>03008944ST-1</th>\n",
       "      <th>03008944ST-3</th>\n",
       "      <th>0300ST1550-1</th>\n",
       "      <th>0300ST15X9-1</th>\n",
       "      <th>0300ST15X9-2</th>\n",
       "      <th>0300ST15X9-3</th>\n",
       "      <th>0300ST1605-1</th>\n",
       "      <th>0300ST1605-2</th>\n",
       "      <th>...</th>\n",
       "      <th>9920-2</th>\n",
       "      <th>9920-3</th>\n",
       "      <th>9920-4</th>\n",
       "      <th>9920-5</th>\n",
       "      <th>9920-6</th>\n",
       "      <th>9920-7</th>\n",
       "      <th>9997-25</th>\n",
       "      <th>HW220D15</th>\n",
       "      <th>HW240DIA</th>\n",
       "      <th>TRUHONE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            012  017  03008944ST-1  03008944ST-3  0300ST1550-1  0300ST15X9-1  \\\n",
       "EntDate                                                                        \n",
       "2017-10-08    0    0             0             0             0             0   \n",
       "2017-10-15    0    0             0             0             0             0   \n",
       "2017-10-22    0    0             0             0             0             0   \n",
       "2017-10-29    0    0             0             0             0             0   \n",
       "2017-11-05    0    0             0             0             0             0   \n",
       "\n",
       "            0300ST15X9-2  0300ST15X9-3  0300ST1605-1  0300ST1605-2   ...     \\\n",
       "EntDate                                                              ...      \n",
       "2017-10-08             0             0             0             0   ...      \n",
       "2017-10-15             0             0             0             0   ...      \n",
       "2017-10-22             0             0             0             0   ...      \n",
       "2017-10-29             0             0             0             0   ...      \n",
       "2017-11-05             0             0             0             0   ...      \n",
       "\n",
       "            9920-2  9920-3  9920-4  9920-5  9920-6  9920-7  9997-25  HW220D15  \\\n",
       "EntDate                                                                         \n",
       "2017-10-08       0       3       0       0       0      13        0         0   \n",
       "2017-10-15       0       0       0       0       0       0        0         0   \n",
       "2017-10-22       0       0       0       0       0       0        0         0   \n",
       "2017-10-29       0       0       0       0       0       0        2         0   \n",
       "2017-11-05       0       0       0       0       0       0        0         0   \n",
       "\n",
       "            HW240DIA  TRUHONE  \n",
       "EntDate                        \n",
       "2017-10-08         0        0  \n",
       "2017-10-15         0        0  \n",
       "2017-10-22         0        0  \n",
       "2017-10-29         0        0  \n",
       "2017-11-05         0        0  \n",
       "\n",
       "[5 rows x 1833 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions import load_data\n",
    "data_df = load_data('data/time_series.xlsx')\n",
    "data_df.info()\n",
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into training and testing sets setting aside last year for testing\n",
    "from functions import ts_train_test_split\n",
    "\n",
    "train_df, test_df = ts_train_test_split(data_df, 52)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split -- alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will make three datasets using 33-33-34\n",
    "X = data_df.values\n",
    "train_size1 = int(len(X) * 0.33)\n",
    "train_size2 = int(len(X) * 0.66)\n",
    "pretrain, train, test = X[0:train_size1], X[train_size1:train_size2], X[train_size2:len(X)]\n",
    "print('Observations: %d' % (len(X)))\n",
    "print('Initializing Observations: %d' % (len(pretrain)))\n",
    "print('Training Observations: %d' % (len(train)))\n",
    "print('Testing Observations: %d' % (len(test)))\n",
    "# made train_df and test_df (the latter to be used later)\n",
    "pretrain_df = data_df[0:train_size1]\n",
    "train_df = data_df[train_size1:train_size2]\n",
    "test_df = data_df[train_size2:292]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select single item for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one item\n",
    "test = train_df['9920-2']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one item\n",
    "from functions import plot_train_test\n",
    "plot_train_test(train_df, test_df, '9920-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make transformations pipeline (first applied to train, then apply to test)\n",
    "# luckily, our data has no null values, no categorical/text values\n",
    "# however, to get the initial messy excel sheet into timeseries format was not easy\n",
    "# describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select Models and Scoring Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are comparing different forecasting models on the same data, so we can use scale-dependent errors because our single dataset only has one scale. We will use two metrics: <br>\n",
    "* MAD (also called MAE): $\\frac{|A_t-F_t|}{n}$ <br>\n",
    "* RMSE (root mean squared error): $\\sqrt{\\frac{(A_t-F_t)^2}{n}}$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For baseline, we will use:\n",
    "* naive forecast (\"only yesterday matters\")\n",
    "\n",
    "Then we will try two simple forecasts:\n",
    "* cumulative (\"history matters\")\n",
    "* moving average (\"I select how much matters\")\n",
    "\n",
    "We will also try:\n",
    "* ARIMA\n",
    "* exponential smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df to store all our predictions\n",
    "from functions import make_copy_df\n",
    "y_hat = make_copy_df(test_df, '9920-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Forecast (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "import numpy as np\n",
    "\n",
    "dd= np.asarray(train_df['9920-2'])\n",
    "y_hat['naive'] = dd[len(dd)-1] # this line of code is for one-time forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "from functions import plot_time_series\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'naive', 'Naive Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', y_hat, 'naive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df, '9920-2', y_hat, 'naive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import cumulative\n",
    "y_hat['cumulative'] = cumulative(train_df['9920-2'])\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'cumulative', 'Cumulative Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'cumulative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecasts for a quarter year do better than half year or full year\n",
    "from functions import moving_average\n",
    "y_hat['moving_avg'] = moving_average(train_df['9920-2'], m=13)\n",
    "\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'moving_avg', 'Moving Average Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'moving_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'moving_avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S/ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch with pyramid\n",
    "from pyramid.arima import ARIMA\n",
    "\n",
    "fit = ARIMA(order=(1, 1, 0), seasonal_order=(1, 0, 0, 12)).fit(y=train_df['9920-2'])\n",
    "\n",
    "from pyramid.arima import auto_arima\n",
    "\n",
    "stepwise_fit = auto_arima(train_df['9920-2'], start_p=0, start_q=0, max_p=6, max_q=6, m=12,\n",
    "                          start_P=0, seasonal=True, d=1, D=1, trace=True,\n",
    "                          error_action='ignore',  # don't want to know if an order does not work\n",
    "                          suppress_warnings=True,  # don't want convergence warnings\n",
    "                          stepwise=True)  # set to stepwise\n",
    "\n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with SARIMAX\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "fit1 = SARIMAX(train_df['9920-2'], order=(0, 1, 1), seasonal_order=(0,1,2,12), freq='W').fit()\n",
    "y_hat['SARIMA'] = fit1.predict(start=\"2016-11-06\", end=\"2017-11-05\", dynamic=True, typ='levels')\n",
    "\n",
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'SARIMA', 'SARIMA Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'SARIMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's decompose it first to see trend, seasonality\n",
    "from functions import decompose_timeseries\n",
    "\n",
    "decompose_timeseries(train_df['9920-2'], 'additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Exponential Smoothing with Statsmodels\n",
    "# no trend, just seasonality (multiplicative), no damping\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "fit1 = ExponentialSmoothing(np.asarray(train_df['9920-2']), seasonal_periods=10, trend=None, seasonal='additive').fit(smoothing_level=0.51, smoothing_seasonal=0.1)\n",
    "y_hat['DES'] = fit1.forecast(len(test_df))\n",
    "\n",
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'DES', 'Double ES Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'DES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# here we have trend and seasonality, so we will use Holt-Winters with Statsmodels\n",
    "# additive trend and seasonality, no trend damping, seasonal periods=10\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "fit1 = ExponentialSmoothing(np.asarray(train_df['9920-2']), seasonal_periods=10, \n",
    "                            trend='additive', seasonal='additive').fit(smoothing_level=0.51, \n",
    "                                                             smoothing_slope=0.015,\n",
    "                                                             smoothing_seasonal=0.1)\n",
    "y_hat['Holt_Winter'] = fit1.forecast(len(test_df))\n",
    "\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'Holt_Winter', 'Holt_Winter Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'Holt_Winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'Holt_Winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### issue 1: lack of gridsearch capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try statsmodels HW with GridSearch -- doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create homemade GridSearch for statsmodel HW -- WORK NEEDED\n",
    "# homemade gridsearch for ARIMA\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import sqrt\n",
    "\n",
    "# evaluate HW model for a given order (p,d,q)\n",
    "def evaluate_holtwinters_model(X, a, b, g):\n",
    "    # prepare training dataset\n",
    "    train_size = int(len(X) * 0.66)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        #model = ARIMA(train, order=arima_order)\n",
    "        model = ExponentialSmoothing(train, seasonal_periods=10, \n",
    "                            trend='add', seasonal='add')\n",
    "        model_fit = model.fit(disp=0, smoothing_level=a, \n",
    "                                    smoothing_slope=b,\n",
    "                                    smoothing_seasonal=g)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    # calculate out of sample error\n",
    "    error = sqrt(mean_squared_error(test, predictions))\n",
    "    return error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def evaluate_models(dataset, a_values, b_values, g_values):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for a in a_values:\n",
    "        for b in b_values:\n",
    "            for g in g_values:\n",
    "                smoothing_level, smoothing_slope, smoothing_seasonal=a, b, g\n",
    "                try:\n",
    "                    mse = evaluate_holtwinters_model(dataset, smoothing_level, smoothing_slope, smoothing_seasonal)\n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, smoothing_level, smoothing_slope, smoothing_seasonal\n",
    "                    print('HW%s RMSE=%.3f' % (smoothing_level, smoothing_slope, smoothing_seasonal,mse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best HW%s RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HWNone RMSE=inf\n"
     ]
    }
   ],
   "source": [
    "dataset = data_df['9920-2']\n",
    "a_values = [0.02, 0.1, 0.19, 0.35, 0.51]\n",
    "b_values = [0.005, 0.029, 0.053, 0.094, 0.135, 0.176]\n",
    "g_values = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "evaluate_models(dataset, a_values, b_values, g_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing with Homebrewed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exponential_smoothing import initial_trend, initial_seasonal_components, triple_exponential_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = triple_exponential_smoothing(train_df['9920-2'], slen=10, alpha=0.51, beta=0.015, gamma=0.1, n_preds=52)\n",
    "y_hat['HW_new'] = predictions[-52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', y_hat, 'HW_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing with Homebrewed Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additive trend and seasonality, no trend damping, seasonal periods=10\n",
    "from HoltWinters_class2 import HoltWinters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HoltWinters(alpha=0.51, beta=0.015, gamma=0.1, n_preds=52)\n",
    "model.fit(train_df['9920-2'])\n",
    "\n",
    "preds = model.predict(train_df['9920-2'])\n",
    "y_hat['Holt_Winter'] = preds[-52:]\n",
    "\n",
    "from functions import plot_time_series\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'Holt_Winter', 'Holt_Winter Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "model.scorer(train_df['9920-2'], test_df['9920-2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### issue 1: lack of gridsearch capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried running checkestimator -- failed\n",
    "# tried gridsearch with custom scoring function -- failed\n",
    "# tried gridsearch after removing regressormixin -- failed\n",
    "# tried gridsearch without score() method inside class -- failed\n",
    "# tried gridsearch after removing regressormixin with custom scoring function -- failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### issue 2: initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the dataframe for Prophet transformations\n",
    "from functions import make_copy_df\n",
    "prophet_df = make_copy_df(train_df, '9920-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables (prophet requires the variable names in the time series to be\n",
    "# y for target and ds for Datetime)\n",
    "from functions import rename_columns\n",
    "rename_columns(prophet_df, '9920-2')\n",
    "prophet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "# set the uncertainty interval to 95% (the Prophet default is 80%)\n",
    "my_model = Prophet(growth='linear', interval_width=0.95, weekly_seasonality=True)\n",
    "my_model.fit(prophet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "future_dates = my_model.make_future_dataframe(periods=52, freq='W')\n",
    "forecast = my_model.predict(future_dates)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "forecast.head()\n",
    "forecast = forecast.set_index('ds')\n",
    "forecast_slice=forecast[240:292]\n",
    "forecast_df = forecast_slice[\"yhat\"]\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', forecast_slice, 'yhat', 'Prophet Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', forecast_slice, 'yhat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great basic blogs on time series and forecasting methods: https://medium.com/@josemarcialportilla/using-python-and-auto-arima-to-forecast-seasonal-time-series-90877adff03c\n",
    "\n",
    "On Prophet:\n",
    "https://www.analyticsvidhya.com/blog/2018/05/generate-accurate-forecasts-facebook-prophet-python-r/\n",
    "https://research.fb.com/prophet-forecasting-at-scale/\n",
    "(Plus see "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
