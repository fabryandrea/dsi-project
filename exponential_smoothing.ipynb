{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_excel('VMI1984_Example.xlsx', header=3)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = data_df['x(t)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Exponential Smoothing (level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle\\hat{x}_{t,t+1}=\\alpha x_t+(1-\\alpha)\\hat{x}_{t-1,t}$ <br>\n",
    "only smoothing param: $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized with first value in series, no scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exponential_smoothing import exponential_smoothing\n",
    "\n",
    "predictions = exponential_smoothing(series, 0.1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rms = sqrt(mean_squared_error(series, predictions))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain = series[0:5] # instead of 28, this prediction starts with 30.2\n",
    "train = series\n",
    "test = series[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SES_class_improved import SimpleExponentialSmoothing\n",
    "model = SimpleExponentialSmoothing(alpha=0.2)\n",
    "model.fit(pretrain, train, test)\n",
    "model.predict(pretrain, train, pred_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(pretrain, train, test, pred_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-75d8317254bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_checks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mSES_class_improved\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleExponentialSmoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcheck_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleExponentialSmoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# passes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/estimator_checks.py\u001b[0m in \u001b[0;36mcheck_estimator\u001b[0;34m(Estimator)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_yield_all_checks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSkipTest\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;31m# the only SkipTest thrown currently results from not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/testing.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/estimator_checks.py\u001b[0m in \u001b[0;36mcheck_estimators_dtypes\u001b[0;34m(name, estimator_orig)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mset_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from SES_class_improved import SimpleExponentialSmoothing\n",
    "check_estimator(SimpleExponentialSmoothing)  # passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(series, alpha):\n",
    "    result = [series[0]] # first value is same as series\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_smoothing(series, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(series, alpha):\n",
    "    result = [series[0]] # first value is same as series\n",
    "    for i, item in enumerate(train):\n",
    "        result.append(alpha * series[i] + (1 - alpha) * result[i-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_smoothing(series, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [series[0]] # first value is same as series\n",
    "alpha = 0.1\n",
    "for i, item in enumerate(train):\n",
    "    result.append(alpha * series[i+1] + (1 - alpha) * result[i])\n",
    "    print(i, item, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [series[0]] # first value is same as series\n",
    "alpha = 0.1\n",
    "for n in range(1, len(series)):\n",
    "    result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    print(n, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt (level + trend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle\\hat{x}_{t,t+\\tau}=\\hat{a}_t+\\tau\\hat{b}_t$ <br>\n",
    "<br>\n",
    "$\\displaystyle\\hat{a}_t=\\alpha x_t+(1-\\alpha)(\\hat{a}_{t-1}+\\hat{b}_{t-1})$ <br>\n",
    "<br>\n",
    "$\\displaystyle\\hat{b}_t=\\beta (\\hat{a}_t - \\hat{a}_{t-1}) + (1-\\beta) \\hat{b}_{t-1}$ <br>\n",
    "<br>\n",
    "smoothing params: $\\alpha$ (level), $\\beta$ (trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized with first value in series (level), and difference between second and first value\n",
    "# in the series ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = data_df['x(t)']\n",
    "\n",
    "from exponential_smoothing import Holt_smoothing\n",
    "\n",
    "Holt_smoothing(series, 0.1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X=data_df['t'].values.reshape(-1, 1)\n",
    "y=data_df['x(t)'].values.reshape(-1, 1)\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X,y)\n",
    "\n",
    "level = lin_model.intercept_\n",
    "trend = lin_model.coef_\n",
    "print(level)\n",
    "print(trend)\n",
    "t = 1\n",
    "a_hat_zero = float(t* trend + level)\n",
    "a_hat_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n",
    "y.shape\n",
    "X=data_df.index\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Exponential Smoothing (level + season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle\\hat{x}_{t,t+\\tau}=\\hat{a}_t+\\tau\\hat{F}_{t+\\tau P}$ <br>\n",
    "<br>\n",
    "$\\displaystyle\\hat{a}_t=\\alpha (\\frac{x_t}{\\hat{F}_{t-P}}) + (1-\\alpha)\\hat{a}_{t-1}$ <br>\n",
    "<br>\n",
    "$\\displaystyle\\hat{F}_t=\\gamma (\\frac{x_t}{\\hat{a}_t}) + (1-\\gamma) \\hat{F}_{t-P}$ <br>\n",
    "<br>\n",
    "smoothing params: $\\alpha$ (level), $\\gamma$ (season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holt-Winters (level + trend + season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINISH FORMULA!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle\\hat{x}_{t,t+\\tau}=\\hat{a}_t+\\tau\\hat{F}_{t+\\tau P}$ <br>\n",
    "<br>\n",
    "$\\displaystyle\\hat{a}_t=\\alpha (\\frac{x_t}{\\hat{F}_{t-P}}) + (1-\\alpha)\\hat{a}_{t-1}$ <br>\n",
    "<br>\n",
    "$\\displaystyle\\hat{F}_t=\\gamma (\\frac{x_t}{\\hat{a}_t}) + (1-\\gamma) \\hat{F}_{t-P}$ <br>\n",
    "<br>\n",
    "smoothing params: $\\alpha$ (level), $\\gamma$ (season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
