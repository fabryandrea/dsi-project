{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get data\n",
    "2. Create train-test split\n",
    "3. Clean training set (write functions): missing values, text, categorical attributes, scaling\n",
    "4. Select models and scoring metrics, then train\n",
    "5. Compare them: clean test set, make predictions, score\n",
    "6. Fine-tune models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 292 entries, 2012-04-08 to 2017-11-05\n",
      "Columns: 1833 entries, 012 to TRUHONE\n",
      "dtypes: int64(1833)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "from functions import load_data\n",
    "data_df = load_data('data/time_series.xlsx')\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 292\n",
      "Training Observations: 240\n",
      "Testing Observations: 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>012</th>\n",
       "      <th>017</th>\n",
       "      <th>03008944ST-1</th>\n",
       "      <th>03008944ST-3</th>\n",
       "      <th>0300ST1550-1</th>\n",
       "      <th>0300ST15X9-1</th>\n",
       "      <th>0300ST15X9-2</th>\n",
       "      <th>0300ST15X9-3</th>\n",
       "      <th>0300ST1605-1</th>\n",
       "      <th>0300ST1605-2</th>\n",
       "      <th>...</th>\n",
       "      <th>9920-2</th>\n",
       "      <th>9920-3</th>\n",
       "      <th>9920-4</th>\n",
       "      <th>9920-5</th>\n",
       "      <th>9920-6</th>\n",
       "      <th>9920-7</th>\n",
       "      <th>9997-25</th>\n",
       "      <th>HW220D15</th>\n",
       "      <th>HW240DIA</th>\n",
       "      <th>TRUHONE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-09</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>293</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            012  017  03008944ST-1  03008944ST-3  0300ST1550-1  0300ST15X9-1  \\\n",
       "EntDate                                                                        \n",
       "2016-10-09    0    0             0             0             0             0   \n",
       "2016-10-16    0    0             0             0             0             0   \n",
       "2016-10-23    0    0             0             0             0             0   \n",
       "2016-10-30    0    0             0             0             0             0   \n",
       "2016-11-06    0    0             0             0             0             0   \n",
       "\n",
       "            0300ST15X9-2  0300ST15X9-3  0300ST1605-1  0300ST1605-2   ...     \\\n",
       "EntDate                                                              ...      \n",
       "2016-10-09             0             0             0             0   ...      \n",
       "2016-10-16             0             0             0             0   ...      \n",
       "2016-10-23             0             0             0             0   ...      \n",
       "2016-10-30             0             0             0             0   ...      \n",
       "2016-11-06             0             0             0             0   ...      \n",
       "\n",
       "            9920-2  9920-3  9920-4  9920-5  9920-6  9920-7  9997-25  HW220D15  \\\n",
       "EntDate                                                                         \n",
       "2016-10-09      12       9       0       0       6       0        0         0   \n",
       "2016-10-16      31       4       5       4      15       2        0         0   \n",
       "2016-10-23     158      27       3     293     199       0        5         0   \n",
       "2016-10-30      23       4       0     221      47       6        1         0   \n",
       "2016-11-06      12      18       8       0      42       1        0         0   \n",
       "\n",
       "            HW240DIA  TRUHONE  \n",
       "EntDate                        \n",
       "2016-10-09         0        0  \n",
       "2016-10-16         0        0  \n",
       "2016-10-23         0        0  \n",
       "2016-10-30         0        0  \n",
       "2016-11-06         0        0  \n",
       "\n",
       "[5 rows x 1833 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting into training and testing sets setting aside last year for testing\n",
    "from functions import ts_train_test_split\n",
    "\n",
    "train_df, test_df = ts_train_test_split(data_df, 52)\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT TOUCH Test Set!!!! Data snooping no-no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1833"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of column names\n",
    "product_SKUs = list(train_df.columns.values)\n",
    "train_df.tail(52)\n",
    "# 2015-11-15 is exactly one year\n",
    "len(product_SKUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non_active products\n",
    "# defined as products that have not moved in n_weeks time periods\n",
    "# we will start with n_weeks 52 (1 year)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def identify_non_active(dataframe, product_list, year, month, day):\n",
    "    last_tp = (dataframe[datetime(year, month, day):])\n",
    "\n",
    "    non_active = []\n",
    "    for product in product_list:\n",
    "        if last_tp[product].sum() == 0:\n",
    "            non_active.append(product)\n",
    "    return non_active\n",
    "\n",
    "non_active = identify_non_active(train_df, product_SKUs, 2015, 11, 4)\n",
    "len(non_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1833 products, 472 non_active, leaving 1361, new?\n",
    "len(product_SKUs) - len(non_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new products \n",
    "train_df[:datetime(2014, 5, 3)]\n",
    "\n",
    "def identify_new_product(dataframe, product_list, year, month, day):\n",
    "    previous_tp = (dataframe[:datetime(year, month, day)])\n",
    "    last_tp = (dataframe[datetime(year, month, day):])\n",
    "\n",
    "    new_products = []\n",
    "    for product in product_list:\n",
    "        if previous_tp[product].sum() == 0 and last_tp[product].sum() !=0:\n",
    "            new_products.append(product)\n",
    "    return new_products\n",
    "new_products = identify_new_product(train_df, product_SKUs, 2015, 11, 4)\n",
    "len(new_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1833 products, 472 non_active, 138 new, leaving 1223, new?\n",
    "len(product_SKUs) - len(non_active) - len(new_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_tp = train_df.tail(12)\n",
    "intermittent = product_SKUs.copy()\n",
    "for product in product_SKUs:\n",
    "    if last_tp[product].sum() == 0:\n",
    "        intermittent.remove(product)\n",
    "len(intermittent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intermittent demand\n",
    "# iterate over last year, if n consecutive values = 0, but sum != 0 \n",
    "# (they are all active so no need to check), it's intermittent\n",
    "def identify_intermittent_product(dataframe, product_list, year, month, day, n):\n",
    "    last_tp = (dataframe[datetime(year, month, day):])\n",
    "\n",
    "    intermittent = product_list.copy()\n",
    "    active = []\n",
    "    for product in product_list:\n",
    "        if last_tp[product].sum() != 0:\n",
    "            active.append(product)\n",
    "    \n",
    "    for product in active:\n",
    "        if last_tp[product].rolling(n).sum().dropna().nonzero():\n",
    "            intermittent.remove(product)\n",
    "    return intermittent\n",
    "    \n",
    "my_list = identify_intermittent_product(train_df, product_SKUs, 2015, 11, 4, 4)\n",
    "len(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>012</th>\n",
       "      <th>017</th>\n",
       "      <th>03008944ST-1</th>\n",
       "      <th>03008944ST-3</th>\n",
       "      <th>0300ST1550-1</th>\n",
       "      <th>0300ST15X9-1</th>\n",
       "      <th>0300ST15X9-2</th>\n",
       "      <th>0300ST15X9-3</th>\n",
       "      <th>0300ST1605-1</th>\n",
       "      <th>0300ST1605-2</th>\n",
       "      <th>...</th>\n",
       "      <th>9920-2</th>\n",
       "      <th>9920-3</th>\n",
       "      <th>9920-4</th>\n",
       "      <th>9920-5</th>\n",
       "      <th>9920-6</th>\n",
       "      <th>9920-7</th>\n",
       "      <th>9997-25</th>\n",
       "      <th>HW220D15</th>\n",
       "      <th>HW240DIA</th>\n",
       "      <th>TRUHONE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-04-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>166</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>207</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>101</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-03</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>177</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>138</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>86</td>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 1833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            012  017  03008944ST-1  03008944ST-3  0300ST1550-1  0300ST15X9-1  \\\n",
       "EntDate                                                                        \n",
       "2012-04-08    0    0             0             0             0             0   \n",
       "2012-04-15    0    0             0             0             0             0   \n",
       "2012-04-22    0    0             0             0             0             0   \n",
       "2012-04-29    0    0             0             0             0             0   \n",
       "2012-05-06    0    0             0             0             0             0   \n",
       "2012-05-13    0    0             0             0             0             0   \n",
       "2012-05-20    0    0             0             0             0             0   \n",
       "2012-05-27    0    0             0             0             0             0   \n",
       "2012-06-03    0    0             0             0             0             0   \n",
       "2012-06-10    0    0             0             0             0             0   \n",
       "2012-06-17    0    0             0             0             0             0   \n",
       "2012-06-24    0    0             0             0             0             0   \n",
       "\n",
       "            0300ST15X9-2  0300ST15X9-3  0300ST1605-1  0300ST1605-2   ...     \\\n",
       "EntDate                                                              ...      \n",
       "2012-04-08             0             0             0             0   ...      \n",
       "2012-04-15             0             0             0             0   ...      \n",
       "2012-04-22             0             0             0             0   ...      \n",
       "2012-04-29             0             0             0             0   ...      \n",
       "2012-05-06             0             0             0             0   ...      \n",
       "2012-05-13             0             0             0             0   ...      \n",
       "2012-05-20             0             0             0             0   ...      \n",
       "2012-05-27             0             0             0             0   ...      \n",
       "2012-06-03             0             0             0             0   ...      \n",
       "2012-06-10             0             0             0             0   ...      \n",
       "2012-06-17             0             0             0             0   ...      \n",
       "2012-06-24             0             0             0             0   ...      \n",
       "\n",
       "            9920-2  9920-3  9920-4  9920-5  9920-6  9920-7  9997-25  HW220D15  \\\n",
       "EntDate                                                                         \n",
       "2012-04-08       0       0       0       0       0       0        0         0   \n",
       "2012-04-15      20      19       7     166      98       0        0         0   \n",
       "2012-04-22      41      15      10     207      87       0        0         0   \n",
       "2012-04-29      38      44      13     101      21      10        0         0   \n",
       "2012-05-06      29      47      21      75      43       0        0         0   \n",
       "2012-05-13      18      35       0     133      34       0        0         0   \n",
       "2012-05-20      42      24       0      90      28       0        0         0   \n",
       "2012-05-27       6      20       6     124      73       0        0         0   \n",
       "2012-06-03      52      36      13     177      26       0        0         0   \n",
       "2012-06-10      12       1       0      67      18       0        0         0   \n",
       "2012-06-17      13      18       8     138      13       0        0         0   \n",
       "2012-06-24      22      22      11      86      52      15        0         0   \n",
       "\n",
       "            HW240DIA  TRUHONE  \n",
       "EntDate                        \n",
       "2012-04-08         0        0  \n",
       "2012-04-15         0        0  \n",
       "2012-04-22         0        0  \n",
       "2012-04-29         0        0  \n",
       "2012-05-06         0        0  \n",
       "2012-05-13         0        0  \n",
       "2012-05-20         0        0  \n",
       "2012-05-27         0        1  \n",
       "2012-06-03         0        0  \n",
       "2012-06-10         0        0  \n",
       "2012-06-17         0        0  \n",
       "2012-06-24         0        0  \n",
       "\n",
       "[12 rows x 1833 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = train_df[0:12]\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntDate\n",
       "2012-04-08    NaN\n",
       "2012-04-15    NaN\n",
       "2012-04-22    NaN\n",
       "2012-04-29    NaN\n",
       "2012-05-06    0.0\n",
       "2012-05-13    0.0\n",
       "2012-05-20    0.0\n",
       "2012-05-27    1.0\n",
       "2012-06-03    1.0\n",
       "2012-06-10    1.0\n",
       "2012-06-17    1.0\n",
       "2012-06-24    1.0\n",
       "Name: TRUHONE, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing2 = testing[\"TRUHONE\"].rolling(5).sum()\n",
    "testing2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntDate\n",
       "2012-05-06    0.0\n",
       "2012-05-13    0.0\n",
       "2012-05-20    0.0\n",
       "2012-05-27    1.0\n",
       "2012-06-03    1.0\n",
       "2012-06-10    1.0\n",
       "2012-06-17    1.0\n",
       "2012-06-24    1.0\n",
       "Name: TRUHONE, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing3 = testing2.dropna()\n",
    "testing3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay\n"
     ]
    }
   ],
   "source": [
    "testing4 = testing[\"TRUHONE\"].rolling(5).sum().dropna()\n",
    "if testing4.nonzero():\n",
    "    print('yay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntDate\n",
       "2012-05-06    0.0\n",
       "2012-05-13    0.0\n",
       "2012-05-20    0.0\n",
       "2012-05-27    1.0\n",
       "2012-06-03    1.0\n",
       "2012-06-10    1.0\n",
       "2012-06-17    1.0\n",
       "2012-06-24    1.0\n",
       "Name: TRUHONE, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing3 = testing2.drop(testing2.index[:4])\n",
    "testing3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9dee14c401f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TRUHONE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'good'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m   1120\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "if testing[\"TRUHONE\"].rolling(5).sum().isnull():\n",
    "    print('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-3e9a11b967ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mintermittent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct_SKUs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mintermittent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m   1120\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "intermittent = []\n",
    "for product in product_SKUs:\n",
    "    if testing[product].rolling(n).sum() == 0:\n",
    "        intermittent.append(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntDate\n",
       "2012-04-08      NaN\n",
       "2012-04-15      NaN\n",
       "2012-04-22     61.0\n",
       "2012-04-29     99.0\n",
       "2012-05-06    108.0\n",
       "2012-05-13     85.0\n",
       "2012-05-20     89.0\n",
       "2012-05-27     66.0\n",
       "2012-06-03    100.0\n",
       "2012-06-10     70.0\n",
       "2012-06-17     77.0\n",
       "2012-06-24     47.0\n",
       "Name: 9920-2, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing['9920-2'].rolling(3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select single item for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one item\n",
    "test = train_df['03108627CC']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one item\n",
    "from functions import plot_train_test\n",
    "plot_train_test(train_df, test_df, '03108627CC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make transformations pipeline (first applied to train, then apply to test)\n",
    "# luckily, our data has no null values, no categorical/text values\n",
    "# however, to get the initial messy excel sheet into timeseries format was not easy\n",
    "# describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select Models and Scoring Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are comparing different forecasting models on the same data, so we can use scale-dependent errors because our single dataset only has one scale. We will use two metrics: <br>\n",
    "* MAD (also called MAE): $\\frac{|A_t-F_t|}{n}$ <br>\n",
    "* RMSE (root mean squared error): $\\sqrt{\\frac{(A_t-F_t)^2}{n}}$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For baseline, we will use:\n",
    "* naive forecast (\"only yesterday matters\")\n",
    "\n",
    "Then we will try two simple forecasts:\n",
    "* cumulative (\"history matters\")\n",
    "* moving average (\"I select how much matters\")\n",
    "\n",
    "We will also try:\n",
    "* ARIMA\n",
    "* exponential smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df to store all our predictions\n",
    "from functions import make_copy_df\n",
    "y_hat = make_copy_df(test_df, '9920-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Forecast (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "import numpy as np\n",
    "\n",
    "dd= np.asarray(train_df['9920-2'])\n",
    "y_hat['naive'] = dd[len(dd)-1] # this line of code is for one-time forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "from functions import plot_time_series\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'naive', 'Naive Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', y_hat, 'naive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df, '9920-2', y_hat, 'naive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import cumulative\n",
    "y_hat['cumulative'] = cumulative(train_df['9920-2'])\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'cumulative', 'Cumulative Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'cumulative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecasts for a quarter year do better than half year or full year\n",
    "from functions import moving_average\n",
    "y_hat['moving_avg'] = moving_average(train_df['9920-2'], m=13)\n",
    "\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'moving_avg', 'Moving Average Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'moving_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'moving_avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S/ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch with pyramid\n",
    "from pyramid.arima import ARIMA\n",
    "\n",
    "fit = ARIMA(order=(1, 1, 0), seasonal_order=(1, 0, 0, 12)).fit(y=train_df['9920-2'])\n",
    "\n",
    "from pyramid.arima import auto_arima\n",
    "\n",
    "stepwise_fit = auto_arima(train_df['9920-2'], start_p=0, start_q=0, max_p=6, max_q=6, m=12,\n",
    "                          start_P=0, seasonal=True, d=1, D=1, trace=True,\n",
    "                          error_action='ignore',  # don't want to know if an order does not work\n",
    "                          suppress_warnings=True,  # don't want convergence warnings\n",
    "                          stepwise=True)  # set to stepwise\n",
    "\n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with SARIMAX\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "fit1 = SARIMAX(train_df['9920-2'], order=(0, 1, 1), seasonal_order=(0,1,2,12), freq='W').fit()\n",
    "y_hat['SARIMA'] = fit1.predict(start=\"2016-11-06\", end=\"2017-11-05\", dynamic=True, typ='levels')\n",
    "\n",
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'SARIMA', 'SARIMA Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'SARIMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's decompose it first to see trend, seasonality\n",
    "from functions import decompose_timeseries\n",
    "\n",
    "decompose_timeseries(train_df['9920-2'], 'additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Exponential Smoothing with Statsmodels\n",
    "# no trend, just seasonality (multiplicative), no damping\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "fit1 = ExponentialSmoothing(np.asarray(train_df['9920-2']), seasonal_periods=10, trend=None, seasonal='additive').fit(smoothing_level=0.51, smoothing_seasonal=0.1)\n",
    "y_hat['DES'] = fit1.forecast(len(test_df))\n",
    "\n",
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'DES', 'Double ES Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'DES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have trend and seasonality, so we will use Holt-Winters with Statsmodels\n",
    "# additive trend and seasonality, no trend damping, seasonal periods=10\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "fit1 = ExponentialSmoothing(np.asarray(train_df['9920-2']), seasonal_periods=10, trend='add', seasonal='add').fit(smoothing_level=0.51, smoothing_slope=0.015,smoothing_seasonal=0.1)\n",
    "y_hat['Holt_Winter'] = fit1.forecast(len(test_df))\n",
    "\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'Holt_Winter', 'Holt_Winter Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'Holt_Winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'Holt_Winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing with Homebrewed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exponential_smoothing import initial_trend, initial_seasonal_components, triple_exponential_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = triple_exponential_smoothing(train_df['9920-2'], slen=10, alpha=0.51, beta=0.015, gamma=0.1, n_preds=52)\n",
    "y_hat['HW_new'] = predictions[-52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', y_hat, 'HW_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing with Homebrewed Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additive trend and seasonality, no trend damping, seasonal periods=10\n",
    "from HoltWinters_class2 import HoltWinters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HoltWinters(alpha=0.51, beta=0.015, gamma=0.1, n_preds=52)\n",
    "model.fit(train_df['9920-2'])\n",
    "\n",
    "preds = model.predict(train_df['9920-2'])\n",
    "y_hat['Holt_Winter'] = preds[-52:]\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'Holt_Winter', 'Holt_Winter Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "model.score(train_df['9920-2'], test_df['9920-2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from HoltWinters_class2 import HoltWinters\n",
    "\n",
    "# create a parameter grid: map the parameter names to the values\n",
    "param_grid = {'alpha': [0.02, 0.1, 0.19, 0.35, 0.51],                   \n",
    "                'beta': [0.005, 0.029, 0.053, 0.094, 0.135, 0.176],\n",
    "                'gamma': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]}\n",
    "# instantiate the grid\n",
    "grid_search = GridSearchCV(HoltWinters(), param_grid)\n",
    "# fit the grid with data\n",
    "grid_search.fit(train_df['9920-2']).score(X=train_df['9920-2'], y=test_df['9920-2'])\n",
    "# print best results\n",
    "grid_search.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parameter grid: map the parameter names to the values\n",
    "param_grid = {'alpha': [0.02, 0.1, 0.19, 0.35, 0.51],                   \n",
    "                'beta': [0.005, 0.029, 0.053, 0.094, 0.135, 0.176],\n",
    "                'gamma': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "              'slen': [10],\n",
    "              'n_preds': [100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the dataframe for Prophet transformations\n",
    "from functions import make_copy_df\n",
    "prophet_df = make_copy_df(train_df, '9920-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables (prophet requires the variable names in the time series to be\n",
    "# y for target and ds for Datetime)\n",
    "from functions import rename_columns\n",
    "rename_columns(prophet_df, '9920-2')\n",
    "prophet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "# set the uncertainty interval to 95% (the Prophet default is 80%)\n",
    "my_model = Prophet(growth='linear', interval_width=0.95, weekly_seasonality=True)\n",
    "my_model.fit(prophet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "future_dates = my_model.make_future_dataframe(periods=52, freq='W')\n",
    "forecast = my_model.predict(future_dates)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "forecast.head()\n",
    "forecast = forecast.set_index('ds')\n",
    "forecast_slice=forecast[240:292]\n",
    "forecast_df = forecast_slice[\"yhat\"]\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', forecast_slice, 'yhat', 'Prophet Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', forecast_slice, 'yhat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great basic blogs on time series and forecasting methods: https://medium.com/@josemarcialportilla/using-python-and-auto-arima-to-forecast-seasonal-time-series-90877adff03c\n",
    "\n",
    "On Prophet:\n",
    "https://www.analyticsvidhya.com/blog/2018/05/generate-accurate-forecasts-facebook-prophet-python-r/\n",
    "https://research.fb.com/prophet-forecasting-at-scale/\n",
    "(Plus see "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
