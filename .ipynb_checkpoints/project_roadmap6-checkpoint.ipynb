{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get data\n",
    "2. Create train-test split\n",
    "3. Clean training set (write functions): missing values, text, categorical attributes, scaling\n",
    "4. Select models and scoring metrics, then train\n",
    "5. Compare them: clean test set, make predictions, score\n",
    "6. Fine-tune models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 292 entries, 2012-04-08 to 2017-11-05\n",
      "Columns: 1833 entries, 012 to TRUHONE\n",
      "dtypes: int64(1833)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "from functions import load_data\n",
    "data_df = load_data('data/time_series.xlsx')\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 292\n",
      "Training Observations: 192\n",
      "Testing Observations: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>012</th>\n",
       "      <th>017</th>\n",
       "      <th>03008944ST-1</th>\n",
       "      <th>03008944ST-3</th>\n",
       "      <th>0300ST1550-1</th>\n",
       "      <th>0300ST15X9-1</th>\n",
       "      <th>0300ST15X9-2</th>\n",
       "      <th>0300ST15X9-3</th>\n",
       "      <th>0300ST1605-1</th>\n",
       "      <th>0300ST1605-2</th>\n",
       "      <th>...</th>\n",
       "      <th>9920-2</th>\n",
       "      <th>9920-3</th>\n",
       "      <th>9920-4</th>\n",
       "      <th>9920-5</th>\n",
       "      <th>9920-6</th>\n",
       "      <th>9920-7</th>\n",
       "      <th>9997-25</th>\n",
       "      <th>HW220D15</th>\n",
       "      <th>HW240DIA</th>\n",
       "      <th>TRUHONE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EntDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-04-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>166</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>207</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>101</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            012  017  03008944ST-1  03008944ST-3  0300ST1550-1  0300ST15X9-1  \\\n",
       "EntDate                                                                        \n",
       "2012-04-08    0    0             0             0             0             0   \n",
       "2012-04-15    0    0             0             0             0             0   \n",
       "2012-04-22    0    0             0             0             0             0   \n",
       "2012-04-29    0    0             0             0             0             0   \n",
       "2012-05-06    0    0             0             0             0             0   \n",
       "\n",
       "            0300ST15X9-2  0300ST15X9-3  0300ST1605-1  0300ST1605-2   ...     \\\n",
       "EntDate                                                              ...      \n",
       "2012-04-08             0             0             0             0   ...      \n",
       "2012-04-15             0             0             0             0   ...      \n",
       "2012-04-22             0             0             0             0   ...      \n",
       "2012-04-29             0             0             0             0   ...      \n",
       "2012-05-06             0             0             0             0   ...      \n",
       "\n",
       "            9920-2  9920-3  9920-4  9920-5  9920-6  9920-7  9997-25  HW220D15  \\\n",
       "EntDate                                                                         \n",
       "2012-04-08       0       0       0       0       0       0        0         0   \n",
       "2012-04-15      20      19       7     166      98       0        0         0   \n",
       "2012-04-22      41      15      10     207      87       0        0         0   \n",
       "2012-04-29      38      44      13     101      21      10        0         0   \n",
       "2012-05-06      29      47      21      75      43       0        0         0   \n",
       "\n",
       "            HW240DIA  TRUHONE  \n",
       "EntDate                        \n",
       "2012-04-08         0        0  \n",
       "2012-04-15         0        0  \n",
       "2012-04-22         0        0  \n",
       "2012-04-29         0        0  \n",
       "2012-05-06         0        0  \n",
       "\n",
       "[5 rows x 1833 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting into training and testing sets using 66-34\n",
    "from functions import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(data_df, 0.66)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split -- alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will make three datasets using 33-33-34\n",
    "X = data_df.values\n",
    "train_size1 = int(len(X) * 0.33)\n",
    "train_size2 = int(len(X) * 0.66)\n",
    "pretrain, train, test = X[0:train_size1], X[train_size1:train_size2], X[train_size2:len(X)]\n",
    "print('Observations: %d' % (len(X)))\n",
    "print('Initializing Observations: %d' % (len(pretrain)))\n",
    "print('Training Observations: %d' % (len(train)))\n",
    "print('Testing Observations: %d' % (len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made train_df and test_df (the latter to be used later)\n",
    "pretrain_df = data_df[0:train_size1]\n",
    "train_df = data_df[train_size1:train_size2]\n",
    "test_df = data_df[train_size2:292]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select single item for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one item\n",
    "test = train_df['9920-2']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one item\n",
    "from functions import plot_train_test\n",
    "plot_train_test(train_df, test_df, '9920-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make transformations pipeline (first applied to train, then apply to test)\n",
    "# luckily, our data has no null values, no categorical/text values\n",
    "# however, to get the initial messy excel sheet into timeseries format was not easy\n",
    "# describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select Models and Scoring Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are comparing different forecasting models on the same data, so we can use scale-dependent errors because our single dataset only has one scale. We will use two metrics: <br>\n",
    "* MAD (also called MAE): $\\frac{|A_t-F_t|}{n}$ <br>\n",
    "* RMSE (root mean squared error): $\\sqrt{\\frac{(A_t-F_t)^2}{n}}$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For baseline, we will use:\n",
    "* naive forecast (\"only yesterday matters\")\n",
    "\n",
    "Then we will try two simple forecasts:\n",
    "* cumulative (\"history matters\")\n",
    "* moving average (\"I select how much matters\")\n",
    "\n",
    "We will also try:\n",
    "* ARIMA\n",
    "* exponential smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df to store all our predictions\n",
    "from functions import make_copy_df\n",
    "y_hat = make_copy_df(test_df, '9920-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Forecast (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "import numpy as np\n",
    "\n",
    "dd= np.asarray(train_df['9920-2'])\n",
    "y_hat['naive'] = dd[len(dd)-1] # this line of code is for one-time forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "from functions import plot_time_series\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'naive', 'Naive Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', y_hat, 'naive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df, '9920-2', y_hat, 'naive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "y_hat['cumulative'] = train_df['9920-2'].mean()\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'cumulative', 'Cumulative Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'cumulative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "# since forecasts are for an entire year, we are using 52 weeks\n",
    "y_hat['moving_avg'] = train_df['9920-2'].rolling(156).mean().iloc[-1]\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'moving_avg', 'Moving Average Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'moving_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'moving_avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S/ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch with pyramid\n",
    "from pyramid.arima import ARIMA\n",
    "\n",
    "fit = ARIMA(order=(1, 1, 0), seasonal_order=(1, 0, 0, 12)).fit(y=train_df['9920-2'])\n",
    "\n",
    "from pyramid.arima import auto_arima\n",
    "\n",
    "stepwise_fit = auto_arima(train_df['9920-2'], start_p=0, start_q=0, max_p=6, max_q=6, m=12,\n",
    "                          start_P=0, seasonal=True, d=1, D=1, trace=True,\n",
    "                          error_action='ignore',  # don't want to know if an order does not work\n",
    "                          suppress_warnings=True,  # don't want convergence warnings\n",
    "                          stepwise=True)  # set to stepwise\n",
    "\n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with SARIMAX\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "fit1 = SARIMAX(train_df['9920-2'], order=(0, 1, 1), seasonal_order=(0,1,1,12), freq='W').fit()\n",
    "y_hat['SARIMA'] = fit1.predict(start=\"2015-12-13\", end=\"2017-11-05\", dynamic=True, typ='levels')\n",
    "\n",
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'SARIMA', 'SARIMA Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'SARIMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE FUNCTION\n",
    "# let's decompose it first to see trend, seasonality\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "series = train_df['9920-2']\n",
    "result_a = seasonal_decompose(series, model='additive')\n",
    "result_a.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE FUNCTION\n",
    "# let's plot it a bit bigger\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1, figsize=(16,10))\n",
    "result_a.trend.plot(ax=ax1, label='Trend')\n",
    "result_a.seasonal.plot(ax=ax2)\n",
    "result_a.resid.plot(ax=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Exponential Smoothing with Statsmodels\n",
    "# no trend, just seasonality (multiplicative), no damping\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "fit1 = ExponentialSmoothing(np.asarray(train_df['9920-2']), seasonal_periods=10, trend=None, seasonal='additive').fit(smoothing_level=0.51, smoothing_seasonal=0.1)\n",
    "y_hat['DES'] = fit1.forecast(len(test_df))\n",
    "\n",
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'DES', 'Double ES Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'DES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have trend and seasonality, so we will use Holt-Winters with Statsmodels\n",
    "# additive trend and seasonality, no trend damping, seasonal periods=10\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "fit1 = ExponentialSmoothing(np.asarray(train_df['9920-2']), seasonal_periods=10, trend='add', seasonal='add').fit(smoothing_level=0.51, smoothing_slope=0.015,smoothing_seasonal=0.1)\n",
    "y_hat['Holt_Winter'] = fit1.forecast(len(test_df))\n",
    "\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'Holt_Winter', 'Holt_Winter Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'Holt_Winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'Holt_Winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing with Homebrewed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exponential_smoothing import initial_trend, initial_seasonal_components, triple_exponential_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = triple_exponential_smoothing(train_df['9920-2'], slen=10, alpha=0.51, beta=0.015, gamma=0.1, n_preds=100)\n",
    "y_hat['HW_new'] = predictions[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', y_hat, 'HW_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing with Homebrewed Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HoltWinters_class import HoltWinters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HoltWinters(alpha=0.51, beta=0.015, gamma=0.1)\n",
    "model.fit(train_df.index, train_df['9920-2'])\n",
    "preds = model.predict(X=train_df['9920-2'], slen=10, n_preds=100)\n",
    "y_hat['HW_Class']=preds[192:292]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', y_hat, 'HW_Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.34503609614828"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "model.score(train_df['9920-2'], test_df['9920-2'], slen=10, n_preds=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the dataframe for Prophet transformations\n",
    "from functions import make_copy_df\n",
    "prophet_df = make_copy_df(train_df, '9920-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables (prophet requires the variable names in the time series to be\n",
    "# y for target and ds for Datetime)\n",
    "from functions import rename_columns\n",
    "rename_columns(prophet_df, '9920-2')\n",
    "prophet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "# set the uncertainty interval to 95% (the Prophet default is 80%)\n",
    "my_model = Prophet(growth='linear', interval_width=0.95, weekly_seasonality=True)\n",
    "my_model.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "future_dates = my_model.make_future_dataframe(periods=100, freq='W')\n",
    "forecast = my_model.predict(future_dates)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "forecast.head()\n",
    "forecast = forecast.set_index('ds')\n",
    "forecast_slice=forecast[192:292]\n",
    "forecast_df = forecast_slice[\"yhat\"]\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', forecast_slice, 'yhat', 'Prophet Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', forecast_slice, 'yhat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great basic blogs on time series and forecasting methods: https://medium.com/@josemarcialportilla/using-python-and-auto-arima-to-forecast-seasonal-time-series-90877adff03c\n",
    "\n",
    "On Prophet:\n",
    "https://www.analyticsvidhya.com/blog/2018/05/generate-accurate-forecasts-facebook-prophet-python-r/\n",
    "https://research.fb.com/prophet-forecasting-at-scale/\n",
    "(Plus see "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
