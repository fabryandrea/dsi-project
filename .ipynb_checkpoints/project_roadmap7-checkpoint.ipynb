{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get data\n",
    "2. Create train-test split\n",
    "3. Clean training set (write functions): missing values, text, categorical attributes, scaling\n",
    "4. Select models and scoring metrics, then train\n",
    "5. Compare them: clean test set, make predictions, score\n",
    "6. Fine-tune models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import load_data\n",
    "data_df = load_data('data/time_series.xlsx')\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into training and testing sets using 66-34\n",
    "from functions import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(data_df, 0.66)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split -- alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will make three datasets using 33-33-34\n",
    "X = data_df.values\n",
    "train_size1 = int(len(X) * 0.33)\n",
    "train_size2 = int(len(X) * 0.66)\n",
    "pretrain, train, test = X[0:train_size1], X[train_size1:train_size2], X[train_size2:len(X)]\n",
    "print('Observations: %d' % (len(X)))\n",
    "print('Initializing Observations: %d' % (len(pretrain)))\n",
    "print('Training Observations: %d' % (len(train)))\n",
    "print('Testing Observations: %d' % (len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made train_df and test_df (the latter to be used later)\n",
    "pretrain_df = data_df[0:train_size1]\n",
    "train_df = data_df[train_size1:train_size2]\n",
    "test_df = data_df[train_size2:292]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select single item for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one item\n",
    "test = train_df['9920-2']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one item\n",
    "from functions import plot_train_test\n",
    "plot_train_test(train_df, test_df, '9920-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make transformations pipeline (first applied to train, then apply to test)\n",
    "# luckily, our data has no null values, no categorical/text values\n",
    "# however, to get the initial messy excel sheet into timeseries format was not easy\n",
    "# describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select Models and Scoring Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are comparing different forecasting models on the same data, so we can use scale-dependent errors because our single dataset only has one scale. We will use two metrics: <br>\n",
    "* MAD (also called MAE): $\\frac{|A_t-F_t|}{n}$ <br>\n",
    "* RMSE (root mean squared error): $\\sqrt{\\frac{(A_t-F_t)^2}{n}}$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For baseline, we will use:\n",
    "* naive forecast (\"only yesterday matters\")\n",
    "\n",
    "Then we will try two simple forecasts:\n",
    "* cumulative (\"history matters\")\n",
    "* moving average (\"I select how much matters\")\n",
    "\n",
    "We will also try:\n",
    "* ARIMA\n",
    "* exponential smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df to store all our predictions\n",
    "from functions import make_copy_df\n",
    "y_hat = make_copy_df(test_df, '9920-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Forecast (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "import numpy as np\n",
    "\n",
    "dd= np.asarray(train_df['9920-2'])\n",
    "y_hat['naive'] = dd[len(dd)-1] # this line of code is for one-time forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "from functions import plot_time_series\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'naive', 'Naive Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', y_hat, 'naive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df, '9920-2', y_hat, 'naive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "y_hat['cumulative'] = train_df['9920-2'].mean()\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'cumulative', 'Cumulative Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'cumulative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "# since forecasts are for an entire year, we are using 52 weeks\n",
    "y_hat['moving_avg'] = train_df['9920-2'].rolling(156).mean().iloc[-1]\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'moving_avg', 'Moving Average Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'moving_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'moving_avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S/ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch with pyramid\n",
    "from pyramid.arima import ARIMA\n",
    "\n",
    "fit = ARIMA(order=(1, 1, 0), seasonal_order=(1, 0, 0, 12)).fit(y=train_df['9920-2'])\n",
    "\n",
    "from pyramid.arima import auto_arima\n",
    "\n",
    "stepwise_fit = auto_arima(train_df['9920-2'], start_p=0, start_q=0, max_p=6, max_q=6, m=12,\n",
    "                          start_P=0, seasonal=True, d=1, D=1, trace=True,\n",
    "                          error_action='ignore',  # don't want to know if an order does not work\n",
    "                          suppress_warnings=True,  # don't want convergence warnings\n",
    "                          stepwise=True)  # set to stepwise\n",
    "\n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with SARIMAX\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "fit1 = SARIMAX(train_df['9920-2'], order=(0, 1, 1), seasonal_order=(0,1,1,12), freq='W').fit()\n",
    "y_hat['SARIMA'] = fit1.predict(start=\"2015-12-13\", end=\"2017-11-05\", dynamic=True, typ='levels')\n",
    "\n",
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'SARIMA', 'SARIMA Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'SARIMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE FUNCTION\n",
    "# let's decompose it first to see trend, seasonality\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "series = train_df['9920-2']\n",
    "result_a = seasonal_decompose(series, model='additive')\n",
    "result_a.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE FUNCTION\n",
    "# let's plot it a bit bigger\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1, figsize=(16,10))\n",
    "result_a.trend.plot(ax=ax1, label='Trend')\n",
    "result_a.seasonal.plot(ax=ax2)\n",
    "result_a.resid.plot(ax=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Exponential Smoothing with Statsmodels\n",
    "# no trend, just seasonality (multiplicative), no damping\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "fit1 = ExponentialSmoothing(np.asarray(train_df['9920-2']), seasonal_periods=10, trend=None, seasonal='additive').fit(smoothing_level=0.51, smoothing_seasonal=0.1)\n",
    "y_hat['DES'] = fit1.forecast(len(test_df))\n",
    "\n",
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'DES', 'Double ES Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'DES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have trend and seasonality, so we will use Holt-Winters with Statsmodels\n",
    "# additive trend and seasonality, no trend damping, seasonal periods=10\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "fit1 = ExponentialSmoothing(np.asarray(train_df['9920-2']), seasonal_periods=10, trend='add', seasonal='add').fit(smoothing_level=0.51, smoothing_slope=0.015,smoothing_seasonal=0.1)\n",
    "y_hat['Holt_Winter'] = fit1.forecast(len(test_df))\n",
    "\n",
    "plot_time_series(train_df, test_df, '9920-2', y_hat, 'Holt_Winter', 'Holt_Winter Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df,'9920-2', y_hat, 'Holt_Winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE\n",
    "from functions import MAE\n",
    "\n",
    "MAE(test_df,'9920-2', y_hat, 'Holt_Winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing with Homebrewed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exponential_smoothing import initial_trend, initial_seasonal_components, triple_exponential_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = triple_exponential_smoothing(train_df['9920-2'], slen=10, alpha=0.51, beta=0.015, gamma=0.1, n_preds=100)\n",
    "y_hat['HW_new'] = predictions[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', y_hat, 'HW_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing with Homebrewed Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additive trend and seasonality, no trend damping, seasonal periods=10\n",
    "from HoltWinters_class2 import HoltWinters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HoltWinters(alpha=0.51, beta=0.015, gamma=0.1)\n",
    "model.fit(train_df['9920-2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "model.score(train_df['9920-2'], test_df['9920-2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from HoltWinters_class2 import HoltWinters\n",
    "\n",
    "# create a parameter grid: map the parameter names to the values\n",
    "param_grid = {'alpha': [0.02, 0.1, 0.19, 0.35, 0.51],                   \n",
    "                'beta': [0.005, 0.029, 0.053, 0.094, 0.135, 0.176],\n",
    "                'gamma': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]}\n",
    "# instantiate the grid\n",
    "grid_search = GridSearchCV(HoltWinters(), param_grid)\n",
    "# fit the grid with data\n",
    "grid_search.fit(train_df['9920-2']).score(train=train_df['9920-2'], test=test_df['9920-2'])\n",
    "# print best results\n",
    "grid_search.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parameter grid: map the parameter names to the values\n",
    "param_grid = {'alpha': [0.02, 0.1, 0.19, 0.35, 0.51],                   \n",
    "                'beta': [0.005, 0.029, 0.053, 0.094, 0.135, 0.176],\n",
    "                'gamma': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "              'slen': [10],\n",
    "              'n_preds': [100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the dataframe for Prophet transformations\n",
    "from functions import make_copy_df\n",
    "prophet_df = make_copy_df(train_df, '9920-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables (prophet requires the variable names in the time series to be\n",
    "# y for target and ds for Datetime)\n",
    "from functions import rename_columns\n",
    "rename_columns(prophet_df, '9920-2')\n",
    "prophet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "# set the uncertainty interval to 95% (the Prophet default is 80%)\n",
    "my_model = Prophet(growth='linear', interval_width=0.95, weekly_seasonality=True)\n",
    "my_model.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "future_dates = my_model.make_future_dataframe(periods=100, freq='W')\n",
    "forecast = my_model.predict(future_dates)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LATER\n",
    "forecast.head()\n",
    "forecast = forecast.set_index('ds')\n",
    "forecast_slice=forecast[192:292]\n",
    "forecast_df = forecast_slice[\"yhat\"]\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plot_time_series(train_df, test_df, '9920-2', forecast_slice, 'yhat', 'Prophet Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "from functions import RMSE\n",
    "\n",
    "RMSE(test_df, '9920-2', forecast_slice, 'yhat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great basic blogs on time series and forecasting methods: https://medium.com/@josemarcialportilla/using-python-and-auto-arima-to-forecast-seasonal-time-series-90877adff03c\n",
    "\n",
    "On Prophet:\n",
    "https://www.analyticsvidhya.com/blog/2018/05/generate-accurate-forecasts-facebook-prophet-python-r/\n",
    "https://research.fb.com/prophet-forecasting-at-scale/\n",
    "(Plus see "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
